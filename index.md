---
layout: default
title: Home
---

<div class="profile-section">
  <div class="profile-image">
    <img src="{{ '/assets/images/profile.jpg' | relative_url }}" alt="Chao Zhang">
  </div>
  <div class="profile-info">
    <h1>Chao Zhang</h1>
    <div class="title">James Edenfield Assistant Professor</div>
    <div class="affiliation"><a href="#">School of Computational Science and Engineering</a></div>
    <div class="affiliation"><a href="#">College of Computing</a></div>
    <div class="affiliation"><a href="#">Georgia Institute of Technology</a></div>
    
    <div class="contact">
      <p><strong>Office:</strong> CODA E1358B</p>
      <p><strong>Address:</strong> 756 W Peachtree St NW, Atlanta, GA 30308</p>
      <p><strong>Email:</strong> <a href="mailto:chaozhang@gatech.edu">chaozhang@gatech.edu</a></p>
    </div>
  </div>
</div>

<div class="research-section">
  <h2>Research</h2>
  
  <p>My research lies in the areas of data science, machine learning, and AI. My goal is to make it easier to build domain-customized foundation models and AI agents for task-solving and decision-making. My technical efforts centers on addressing key challenges in <em>data efficiency</em>, <em>computation efficiency</em>, and <em>model robustness</em>. On the application front, I am deeply interested in harnessing foundation models to advance <em>AI for science</em>.</p>
  
  <p>Currently, I am working on the following themes:</p>
  
  <div class="research-themes">
    <div class="research-theme">
      <h3 id="data-centric-llm">1. Data-Centric LLM</h3>
      <p>Adapting Large Language Models for target domains by addressing data scarcity challenges through data-efficient methods such as <em>learning from weak supervision</em> and <em>active learning</em>.</p>
    </div>
    
    <div class="research-theme">
      <h3 id="llm-agents">2. LLM Agents & Reasoning</h3>
      <p>Improving LLM reasoning and planning abilities by enabling them to learn and evolve through <em>interaction with external environments for feedback</em>. The goal is to better adapt LLMs and enhance their reasoning capabilities without expensive manual curation of fine-tuning data.</p>
    </div>
    
    <div class="research-theme">
      <h3 id="ai-alignment">3. AI Alignment</h3>
      <p>Ensuring responsible and reliable deployment of AI through critical techniques including <em>uncertainty quantification</em>, enhancing <em>LLM factuality</em>, and improving <em>LLM alignment</em>.</p>
    </div>
    
    <div class="research-theme">
      <h3 id="ai-for-science">4. AI for Science</h3>
      <p>Leveraging foundation models and AI agents to accelerate scientific discovery in diverse fields such as <em>material science</em>, <em>biomedical and life sciences</em>, and <em>urban science</em>.</p>
    </div>
  </div>
  
  <div class="acknowledgment">
    <p><strong>Acknowledgment:</strong> My work has been generously supported by research funding/gift from NSF (<a href="#">IIS CAREER-2144338</a>, <a href="#">IIS-2106961</a>, <a href="#">IIS-2008334</a>), <a href="#">ONR MURI</a>, Kolon, HomeDepot, ADP, and Adobe. My work has also been recognized by an NSF CAREER Award, a Facebook Faculty Award, an Amazon AWS Machine Learning Research Award, a Google Faculty Research Award, a Kolon Faculty Fellowship, an ACM WSDM Best Paper Award, and a SIAM SDM Best Paper Award.</p>
  </div>
</div>